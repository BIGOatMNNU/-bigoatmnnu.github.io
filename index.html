<html>

<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="style.css" />
    <title>大数据研究实验室</title>

</head>

<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top"><img src="bigo.jpg" style="float: left;" height="56px;" width="146px;"/>
<h1 style="padding-left: 0.5em">大数据研究实验室</h1><hr>
<td id="layout-menu">
    <div class="menu-item"><a href="index.html" class="current">首页</a></div>
	<div class="menu-item"><a href="team.html">师资队伍</a></div>
    <div class="menu-item"><a href="research.html">研究方向</a></div>
	<div class="menu-item"><a href="academic_papers.html">学术论文 </a></div>
	<div class="menu-item"><a href="news.html">最新资讯 </a></div>
	<div class="menu-item"><a href="enrollment_of_master.html">硕士招生</a></div>
    <div class="menu-item"><a href="research_group1.html">研究团队</a></div>
	<div class="menu-item"><a href="life_and_entertainment.html">生活娱乐 </a></div>
    <!--<div class="menu-item"><a href="publication.html">Publications</a></div>-->
    <!--<div class="menu-item"><a href="teaching.html">Teaching</a></div>-->
    <!--<div class="menu-item"><a href="seminar.html">ML Seminar</a></div>-->
</td>
<td id="layout-content">
    <hr>
    <h1 style="margin-top: 0em">首页</h1><br>
  <!--  <p>[ <a href="#news">News</a>,
        <a href="#interest">Research Interests</a>,
        <a href="#job">Job Experience</a>,
        <a href="#edu">Education</a> ]</p>-->
	<div>
		<p class="center"><img src="images/index/index01.jpg" style="width: 800px;height: 500px;" /></p>
	</div>
    <table class="imgtable"><tr valign="top">
        <!-- <td><img src="bhan.jpg" alt="Bo Han" /></td> -->
        
        <td align="left">
            <p><span style="font-size: 130%" ><b><h2 style="text-align: center;"><font style="text-align: center;">大数据研究实验室</font></h2></b></span></p>
            <p>
  				&emsp;&emsp;BiGo大数据研究实验室是闽南师范大学计算机学院林耀进老师指导下的科研团队，大数据研究实验室现有硕士生导师2人，在读研究生18人。<br />
  				实验室的研究方向主要有流环境知识发现、因果发现学习、不一致性学习、层次分类学习等。实验室成员发表多篇论文，取得了较好的成绩。
			</p>
			
			<p>
                &emsp;&emsp;BiGo Big Data Research Laboratory is a scientific research team under the guidance of Professor Lin Yao-jin, School of Computer Science, Minnan Normal University. 
                There are 2 master supervisors and 18 postgraduate students in the Big Data Research Laboratory.The research directions of the laboratory are flow environmental knowledge 
                discovery, causal discovery learning, inconsistency learning, hierarchical classification learning, etc.The lab members have published many papers and achieved good results.
            </p>

            <p>
            	联系方式：
                E-mail： zzlinyaojin@163.com 或yjlin@mnnu.edu.cn<br />实验室：
                <a href="https://github.com/BIGOatMNNU" target="_blank">[Github]</a><br>

            </p>
        </td>
    </tr></table>

 <!--<div>
        <h2><hr><a name="news"></a>师资队伍</h2>
		<ul>
		大数据研究实验室现有硕士生导师2人，在读研究生18人。导师林耀进是闽南师范大学计算机学院院长合肥工业大学博士，天津大学博士后，曾获福建省优秀教师、福建省青年五四奖章、福建省高校新世纪优秀人才、福建省高校杰出青年科研人才等称号。同时中国人工智能学会粒计算与知识发现专委会委员，福建省人工智能学会副理事长。
		</ul>
	  <ul>
		   <li><p><a href="https://wsl-workshop.github.io/acml20.html" target="_blank">林耀进</a>：闽南师范大学计算机学院院长、教授 </p></li>
		   <li><p><a href="https://wsl-workshop.github.io/acml20.html" target="_blank">王晨曦</a>：闽南师范大学计算机学院副教授</p></li>
        </ul>
    </div>

    <div>
        <h2><hr><a name="research"></a>研究方向</h2>
<ul>
&emsp;&emsp;机器学习是近20多年兴起的一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。机器学习理论主要是设计和分析一些让计算机可以自动“学习”的算法。机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。因为学习算法中涉及了大量的统计学理论，机器学习与统计推断学联系尤为密切，也被称为统计学习理论。算法设计方面，机器学习理论关注可以实现的，行之有效的学习算法。很多推论问题属于无程序可循难度，所以部分的机器学习研究是开发容易处理的近似算法。
</ul>
<ul>
&emsp;&emsp;机器学习已经有了十分广泛的应用，例如：数据挖掘、计算机视觉、自然语言处理、生物特征识别、搜索引擎、医学诊断、检测信用卡欺诈、证券市场分析、DNA序列测序、语音和手写识别、战略游戏和机器人运用。本实验室的研究方向主要分为以下六类：</ul>
</ul>

<ul>
<li><p><a href="http://papers.nips.cc/paper/8072-co-teaching-robust-training-o" target="_blank">多标记学习</a></p></li>
<img src="aip-beta.jpg" alt="RIKEN-AIP" />
<li><p><a href="https://arxiv.org/abs/2002.11242" target="_blank">流特征学习</a></p></li>
<li><p> <a href="https://arxiv.org/abs/1911.02377" target="_blank">因果发现学习</a></p></li>
<li><p><a href="https://arxiv.org/abs/2002.11242" target="_blank">深度学习</a></p></li>
<li><p><a href="https://arxiv.org/abs/1911.02377" target="_blank">不一致性学习</a></p></li>
<li><p><a href="https://arxiv.org/abs/2002.11242" target="_blank">层次分类学习</a></p></li>
</ul>

</div>

    <div>
        <h2><hr><a name="tutorials-workshops"></a>学术论文</h2>
        <ul>
		   <li><p>ACML 2020 Workshop on <a href="https://wsl-workshop.github.io/acml20.html" target="_blank">Weakly-supervised Representation Learning</a> (with Tongliang Liu, Mingming Gong, Quanming Yao, Gang Niu, Ivor W. Tsang, Masashi Sugiyama).</p></li>
		   <li><p>SDM 2020 Workshop on <a href="https://wsl-workshop.github.io/sdm20.html" target="_blank">Weakly-supervised and Unsupervised Learning</a> (with Mingming Gong, Chunyuan Li, Tongliang Liu, Quanming Yao, Gang Niu, Kun Zhang, Masashi Sugiyama).</p></li>
		   <li><p>ACML 2019 Workshop on <a href="http://www.acml-conf.org/2019/workshops/weakly-supervised/" target="_blank">Weakly-supervised Learning</a> (with Gang Niu, Quanming Yao, Giogio Patrini, Aditya Menon, Clayton Scott and Masashi Sugiyama).</p></li>
		   <li><p>ACML 2019 Tutorial on <a href="http://www.acml-conf.org/2019/tutorials/tsang-han/" target="_blank">Towards Noisy Supervision: Problems, Theories, and Algorithms</a> (with Ivor W. Tsang).</p></li>
		   <li><p>ACML 2019 Challenge on <a href="https://www.4paradigm.com/competition/autowsl2019" target="_blank">AutoML for Weakly-supervised Learning (AutoWSL)</a> (with Quanming Yao, Wei-Wei Tu, Isabelle Guyon, and Qiang Yang).</p></li>
        </ul>
    
	</div>
    <div>
        <h2><hr><a name="publications"></a> 最新资讯</h2> (* indicates advisees/co-advisees)
        <ul>
		   <li><p>A Survey of Label-noise Representation Learning: Past, Present and Future.<br>
		   <b>B. Han</b>, Q. Yao, T. Liu, G. Niu, I.W. Tsang, J.T. Kwok and M. Sugiyama.<br>
		   <i>arXiv preprint arXiv:2011.04406</i>, 2020, [<a href="https://arxiv.org/pdf/2011.04406.pdf" target="_blank">PDF</a>].<br>
		   (the draft is kept updating; any comments and suggestions are welcome)</p></li>
		   <li><p>Maximum Mean Discrepancy is Aware of Adversarial Attacks.<br>
		   R. Gao*, F. Liu, J. Zhang, <b>B. Han</b>, T. Liu, G. Niu, and M. Sugiyama.<br>
		   <i>arXiv preprint arXiv:2010.11415</i>, 2020, [<a href="https://arxiv.org/pdf/2010.11415.pdf" target="_blank">PDF</a>].</p></li>
		   <li><p>Geometry-aware Instance-reweighted Adversarial Training.<br>
		   J. Zhang, J. Zhu*, G. Niu, <b>B. Han</b>, M. Sugiyama, and M. Kankanhalli.<br>
		   <i>arXiv preprint arXiv:2010.01736</i>, 2020, [<a href="https://arxiv.org/pdf/2010.01736.pdf" target="_blank">PDF</a>].</p></li>
		   <li><p>Pointwise Binary Classification with Pairwise Confidence Comparisons.<br>
		   L. Feng, S. Shu, N. Lu, <b>B. Han</b>, M. Xu, G. Niu, B. An, and M. Sugiyama.<br>
		   <i>arXiv preprint arXiv:2010.01875</i>, 2020, [<a href="https://arxiv.org/pdf/2010.01875.pdf" target="_blank">PDF</a>].</p></li>
		   <li><p>Confidence Scores Make Instance-dependent Label-noise Learning Possible.<br>
		   A. Berthon, <b>B. Han</b>, G. Niu, T. Liu, and M. Sugiyama.<br>
		   <i>arXiv preprint arXiv:2001.03772</i>, 2020, [<a href="https://arxiv.org/pdf/2001.03772.pdf" target="_blank">PDF</a>].</p></li>
		   <li><p>Butterfly: One-step Approach towards Wildly Unsupervised Domain Adaptation.<br>
		   F. Liu*, J. Lu, <b>B. Han</b>, G. Niu, G. Zhang, and M. Sugiyama.<br>
		   <i>arXiv preprint arXiv:1905.07720</i>, 2019, [<a href="https://arxiv.org/pdf/1905.07720.pdf" target="_blank">PDF</a>].</p></li>
		   <li><p>Provably Consistent Partial-Label Learning.<br>
		   L. Feng, J. Lv, <b>B. Han</b>, M. Xu, G. Niu, X. Geng, B. An, and M. Sugiyama.<br>
		   In <i>Advances in Neural Information Processing Systems 33 (NeurIPS'20)</i>, [<a href="https://arxiv.org/abs/2007.08929" target="_blank">PDF</a>] [<a href="https://lfeng1995.github.io/Codes/RCCC.rar" target="_blank">Code</a>].</p></li>
		   <li><p>Dual T: Reducing Estimation Error for Transition Matrix in Label-noise Learning.<br>
		   Y. Yao, T. Liu, <b>B. Han</b>, M. Gong, J. Deng, G. Niu, and M. Sugiyama.<br>
		   In <i>Advances in Neural Information Processing Systems 33 (NeurIPS'20)</i>, [<a href="https://arxiv.org/abs/2006.07805" target="_blank">PDF</a>].</p></li>
		   <li><p>Parts-dependent Label Noise: Towards Instance-dependent Label Noise.<br>
		   X. Xiao, T. Liu, <b>B. Han</b>, N. Wang, M. Gong, H. Liu, G. Niu, D. Tao, and M. Sugiyama.<br>
		   In <i>Advances in Neural Information Processing Systems 33 (NeurIPS'20)</i>, [<a href="https://arxiv.org/abs/2006.07836" target="_blank">PDF</a>].</p></li>
		   <li><p>SIGUA: Forgetting May Make Learning with Noisy Labels More Robust.<br>
		   <b>B. Han</b>, G. Niu, X. Yu, Q. Yao, M. Xu, I.W. Tsang, and M. Sugiyama.<br>
		   In Proceedings of <i>37th International Conference on Machine Learning (ICML'20)</i>, [<a href="https://proceedings.icml.cc/static/paper_files/icml/2020/705-Paper.pdf" target="_blank">PDF</a>] [<a href="https://github.com/bhanML/SIGUA" target="_blank">Code</a>] [<a href="https://icml.cc/virtual/2020/poster/5866" target="_blank">Poster</a>].</p></li>
		   <li><p>Variational Imitation Learning from Diverse-quality Demonstrations.<br>
		   V. Tangkaratt, <b>B. Han</b>, M. Khan, and M. Sugiyama.<br>
		   In Proceedings of <i>37th International Conference on Machine Learning (ICML'20)</i>, [<a href="https://arxiv.org/abs/1909.06769" target="_blank">PDF</a>] [<a href="https://github.com/voot-t/vild_code" target="_blank">Code</a>] [<a href="https://icml.cc/virtual/2020/poster/5846" target="_blank">Poster</a>].</p></li>
		   <li><p>Attacks Which Do Not Kill Training Make Adversarial Learning Stronger.<br>
		   J. Zhang*, X. Xu, <b>B. Han</b>, G. Niu, L. Cui, M. Sugiyama, and M. Kankanhalli.<br>
		   In Proceedings of <i>37th International Conference on Machine Learning (ICML'20)</i>, [<a href="https://proceedings.icml.cc/static/paper_files/icml/2020/520-Paper.pdf" target="_blank">PDF</a>] [<a href="https://github.com/zjfheart/Friendly-Adversarial-Training" target="_blank">Code</a>] [<a href="https://icml.cc/virtual/2020/poster/5835" target="_blank">Poster</a>].</p></li>
		   <li><p>Searching to Exploit Memorization Effect in Learning from Noisy Labels.<br>
		   Q. Yao, H. Yang, <b>B. Han</b>, G. Niu, and J.T. Kwok.<br>
		   In Proceedings of <i>37th International Conference on Machine Learning (ICML'20)</i>, [<a href="https://proceedings.icml.cc/static/paper_files/icml/2020/3285-Paper.pdf" target="_blank">PDF</a>] [<a href="https://github.com/AutoML-4Paradigm/S2E" target="_blank">Code</a>] [<a href="https://icml.cc/virtual/2020/poster/6326" target="_blank">Poster</a>].</p></li>
		   <li><p>Learning with Multiple Complementary Labels.<br>
		   L. Feng, T. Kaneko, <b>B. Han</b>, G. Niu, B. An, and M. Sugiyama.<br>
		   In Proceedings of <i>37th International Conference on Machine Learning (ICML'20)</i>, [<a href="https://proceedings.icml.cc/static/paper_files/icml/2020/1969-Paper.pdf" target="_blank">PDF</a>] [<a href="https://lfeng1995.github.io/Codes/LMCL.rar" target="_blank">Code</a>] [<a href="https://icml.cc/virtual/2020/poster/6084" target="_blank">Poster</a>].</p></li>
		   <li><p>Are Anchor Points Really Indispensable in Label-noise Learning?<br>
		   X. Xiao, T. Liu, N. Wang, <b>B. Han</b>, C. Gong, G. Niu, and M. Sugiyama.<br>
		   In <i>Advances in Neural Information Processing Systems 32 (NeurIPS'19)</i>, [<a href="https://arxiv.org/abs/1906.00189" target="_blank">PDF</a>] [<a href="https://github.com/xiaoboxia/T-Revision" target="_blank">Code</a>] [<a href="https://tongliang-liu.github.io/papers/NeurIPS2019arePoster.pdf" target="_blank">Poster</a>].</p></li>
           <li><p>How does Disagreement Help Generalization against Label Corruption?<br>
		   X. Yu*, <b>B. Han</b>, J. Yao, G. Niu, I.W. Tsang, and M. Sugiyama.<br>
		   In Proceedings of <i>36th International Conference on Machine Learning (ICML'19)</i>, [<a href="http://proceedings.mlr.press/v97/yu19b.html" target="_blank">PDF</a>] [<a href="https://github.com/xingruiyu/coteaching_plus" target="_blank">Code</a>] [<a href="https://icml.cc/media/Slides/icml/2019/halla(12-16-00)-12-16-00-4938-how_does_disagr.pdf" target="_blank">Slides</a>] [<a href="papers/coteaching_plus_poster.pdf" target="_blank">Poster</a>].</p></li>
		   <li><p>Efficient Nonconvex Regularized Tensor Completion with Structure-aware Proximal Iterations.<br>
		   Q. Yao, J.T. Kwok, and <b>B. Han</b>.<br>
		   In Proceedings of <i>36th International Conference on Machine Learning (ICML'19)</i>, [<a href="http://proceedings.mlr.press/v97/yao19a.html" target="_blank">PDF</a>] [<a href="https://github.com/quanmingyao/FasTer" target="_blank">Code</a>] [<a href="https://icml.cc/Conferences/2019/Schedule?showEvent=5191" target="_blank">Poster</a>].</p></li>
		   <li><p>Towards Robust ResNet: A Small Step but A Giant Leap.<br>
		   J. Zhang*, <b>B. Han</b>, L. Wynter, B. Low, and M. Kankanhalli.<br>
		   In Proceedings of <i>28th International Joint Conference on Artificial Intelligence (IJCAI'19)</i>, [<a href="https://www.ijcai.org/proceedings/2019/595" target="_blank">PDF</a>] [<a href="https://github.com/zjfheart/Robust-ResNet" target="_blank">Code</a>] [<a href="papers/robust_resnet_poster.pdf" target="_blank">Poster</a>].</p></li>
		   <li><p>Privacy-preserving Stochastic Gradual Learning.<br>
		    <b>B. Han</b>, I.W. Tsang, X. Xiao, L. Chen, S.-F. Fung, and C. Yu.<br>
			<i>IEEE Transactions on Knowledge and Data Engineering (TKDE)</i>, 2019, [<a href="https://ieeexplore.ieee.org/document/8949708" target="_blank">PDF</a>].</p></li>
		   <li><p>Co-teaching: Robust Training of Deep Neural Networks with Extremely Noisy Labels.<br>
		   <b>B. Han</b>, Q. Yao, X. Yu, G. Niu, M. Xu, W. Hu, I.W. Tsang, and M. Sugiyama.<br>
			In <i>Advances in Neural Information Processing Systems 31 (NeurIPS'18)</i>, [<a href="https://papers.nips.cc/paper/8072-co-teaching-robust-training-of-deep-neural-networks-with-extremely-noisy-labels" target="_blank">PDF</a>] [<a href="https://github.com/bhanML/Co-teaching" target="_blank">Code</a>] [<a href="papers/coteaching_poster.pdf" target="_blank">Poster</a>].</p></li>
		   <li><p>Masking: A New Perspective of Noisy Supervision.<br>
			<b>B. Han</b>, J. Yao, G. Niu, M. Zhou, I.W. Tsang, Y. Zhang, and M. Sugiyama.<br>
			In <i>Advances in Neural Information Processing Systems 31 (NeurIPS'18)</i>, [<a href="https://papers.nips.cc/paper/7825-masking-a-new-perspective-of-noisy-supervision" target="_blank">PDF</a>] [<a href="https://github.com/bhanML/Masking" target="_blank">Code</a>] [<a href="papers/masking_poster.pdf" target="_blank">Poster</a>].</p></li>
		    <li><p>Millionaire: A Hint-guided Approach for Crowdsourcing.<br>
			<b>B. Han</b>, Q. Yao, Y. Pan, I.W. Tsang, X. Xiao, Q. Yang, and M. Sugiyama.<br>
			<i>Machine Learning Journal (MLJ)</i>, 108(5): 831–858, 2018, [<a href="https://link.springer.com/article/10.1007/s10994-018-5766-5" target="_blank">PDF</a>] [<a href="papers/bhan_acml18.pdf" target="_blank">Slides</a>].</p></li>
		    <li><p>Stagewise Learning for Noisy k-ary Preferences.<br>
			Y. Pan, <b>B. Han</b>, and I.W. Tsang.<br>
			<i>Machine Learning Journal (MLJ)</i>, 107: 1333–1361, 2018, [<a href="https://link.springer.com/article/10.1007/s10994-018-5716-2" target="_blank">PDF</a>].</p></li>
            <li><p>Robust Plackett-Luce Model for k-ary Crowdsourced Preferences.<br>
			<b>B. Han</b>, Y. Pan, and I.W. Tsang.<br>
			<i>Machine Learning Journal (MLJ)</i>, 107(4): 675–702, 2017, [<a href="https://link.springer.com/article/10.1007/s10994-017-5674-0" target="_blank">PDF</a>].</p></li>
        </ul>
    </div>
	
	<div>
        <h2><hr><a name="biography"></a>硕士招生</h2>
        <ul>
           大数据研究实验室至2020年有xx个硕士名额，其中，学硕名额xx个，专硕名额xx个。<br>
		   有意加入大数据研究实验室的硕士考生，请发邮件与本实验室导师联系。导师联系方式如下：林耀进：xxxxx.edu.cn &emsp;&emsp;王晨曦：xxxxx.edu.cn 
		   
        </ul>
    </div>

	<div>
        <h2><hr><a name="tutorials-workshops"></a>人才培养</h2>
        <ul>
		   <li><p>白盛兴 <a href="https://wsl-workshop.github.io/acml20.html" target="_blank">Weakly-supervised Representation Learning</a> (with Tongliang Liu, Mingming Gong, Quanming Yao, Gang Niu, Ivor W. Tsang, Masashi Sugiyama).</p></li>
		   <li><p>陈祥焰<a href="https://wsl-workshop.github.io/sdm20.html" target="_blank">Weakly-supervised and Unsupervised Learning</a> (with Mingming Gong, Chunyuan Li, Tongliang Liu, Quanming Yao, Gang Niu, Kun Zhang, Masashi Sugiyama).</p></li>
		   <li><p>陈超逸<a href="http://www.acml-conf.org/2019/workshops/weakly-supervised/" target="_blank">Weakly-supervised Learning</a> (with Gang Niu, Quanming Yao, Giogio Patrini, Aditya Menon, Clayton Scott and Masashi Sugiyama).</p></li>
		   <li><p>吕彦<a href="http://www.acml-conf.org/2019/tutorials/tsang-han/" target="_blank">Towards Noisy Supervision: Problems, Theories, and Algorithms</a> (with Ivor W. Tsang).</p></li>
		   <li><p>卢舜<a href="https://www.4paradigm.com/competition/autowsl2019" target="_blank">AutoML for Weakly-supervised Learning (AutoWSL)</a> (with Quanming Yao, Wei-Wei Tu, Isabelle Guyon, and Qiang Yang).</p></li>
        </ul>
    
	</div>

<div>
        <h2><hr><a name="tutorials-workshops"></a>生活娱乐</h2>
        <ul>
		   <li><p>ACML 2020 Workshop on <a href="https://wsl-workshop.github.io/acml20.html" target="_blank">Weakly-supervised Representation Learning</a> (with Tongliang Liu, Mingming Gong, Quanming Yao, Gang Niu, Ivor W. Tsang, Masashi Sugiyama).</p></li>
		   <li><p>SDM 2020 Workshop on <a href="https://wsl-workshop.github.io/sdm20.html" target="_blank">Weakly-supervised and Unsupervised Learning</a> (with Mingming Gong, Chunyuan Li, Tongliang Liu, Quanming Yao, Gang Niu, Kun Zhang, Masashi Sugiyama).</p></li>
		   <li><p>ACML 2019 Workshop on <a href="http://www.acml-conf.org/2019/workshops/weakly-supervised/" target="_blank">Weakly-supervised Learning</a> (with Gang Niu, Quanming Yao, Giogio Patrini, Aditya Menon, Clayton Scott and Masashi Sugiyama).</p></li>
		   <li><p>ACML 2019 Tutorial on <a href="http://www.acml-conf.org/2019/tutorials/tsang-han/" target="_blank">Towards Noisy Supervision: Problems, Theories, and Algorithms</a> (with Ivor W. Tsang).</p></li>
		   <li><p>ACML 2019 Challenge on <a href="https://www.4paradigm.com/competition/autowsl2019" target="_blank">AutoML for Weakly-supervised Learning (AutoWSL)</a> (with Quanming Yao, Wei-Wei Tu, Isabelle Guyon, and Qiang Yang).</p></li>
        </ul>
    
	</div>

    <div>
    <h2><hr><a name="sponsors"></a>Sponsors</h2>
    <img src="aip-beta.jpg" alt="RIKEN-AIP" />
    <img src="logo-ircn-beta.jpg" alt="International Research Center for Neurointelligence" />
    </div>-->
<!-- <script src="//t1.extreme-dm.com/f.js" id="eXF-bhan-0" async defer></script>-->

</td>
</tr>
</table>
</body>
</html>
